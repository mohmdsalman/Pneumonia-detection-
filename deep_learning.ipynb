{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\Pc\\Desktop\\x-ray project  pnumonia\\chest x-ray pnumonia\\chest_xray\"\n",
    "test_path = r\"C:\\Users\\Pc\\Desktop\\x-ray project  pnumonia\\chest x-ray pnumonia\\chest_xray\\test\"\n",
    "train_path = r\"C:\\Users\\Pc\\Desktop\\x-ray project  pnumonia\\chest x-ray pnumonia\\chest_xray\\train\"\n",
    "\n",
    "category = [\"NORMAL\", \"PNEUMONIA\"]\n",
    "\n",
    "# function to clean and  convert images\n",
    "def clean_and_convert(directory):\n",
    "    for  category in os.listdir(directory):\n",
    "        category_path=os.path.join(directory,category)\n",
    "        for  img_name in os.listdir(category_path):\n",
    "            img_path=os.path.join(category_path,img_name)\n",
    "            try:\n",
    "                with Image.open(img_path) as  img:\n",
    "                    # convert to RGB  and  save as JPEG if not already\n",
    "                    if  img.format !=\"JPEG\":\n",
    "                        img=img.convert(\"RGB\")\n",
    "                        new_img_path=os.path.splitext(img_path)[0]+'jpg'\n",
    "                        img.save(new_img_path,'JPEG')\n",
    "                        os.remove(img_path) # remove the  old file\n",
    "                        print(f\"converted and  saved:{new_img_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Removing corrupted or  unreadable image:{img_path} - {e}\")\n",
    "                os.remove(img_path)# remove corrupted or unreadable files\n",
    "\n",
    "# clean both train and  val directories\n",
    "clean_and_convert(train_path)\n",
    "clean_and_convert(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Define the number of extra copies needed\n",
    "extra_copies = 2534\n",
    "\n",
    "# Source and target folders\n",
    "normal_dir = os.path.join(train_path, \"NORMAL\")\n",
    "\n",
    "for i in range(extra_copies):\n",
    "    src_img = os.path.join(normal_dir, os.listdir(normal_dir)[i % len(os.listdir(normal_dir))])\n",
    "    dst_img = os.path.join(normal_dir, f\"copy_{i}.jpg\")\n",
    "    shutil.copy(src_img, dst_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7766 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\Pc\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1619s\u001b[0m 7s/step - accuracy: 0.7783 - loss: 0.6906 - val_accuracy: 0.8397 - val_loss: 0.3653 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1519s\u001b[0m 6s/step - accuracy: 0.9102 - loss: 0.2505 - val_accuracy: 0.8446 - val_loss: 0.3469 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1507s\u001b[0m 6s/step - accuracy: 0.9222 - loss: 0.2051 - val_accuracy: 0.8478 - val_loss: 0.3625 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1499s\u001b[0m 6s/step - accuracy: 0.9235 - loss: 0.2105 - val_accuracy: 0.7933 - val_loss: 0.4485 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1516s\u001b[0m 6s/step - accuracy: 0.9260 - loss: 0.2021 - val_accuracy: 0.8670 - val_loss: 0.3195 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1503s\u001b[0m 6s/step - accuracy: 0.9292 - loss: 0.1924 - val_accuracy: 0.8750 - val_loss: 0.2994 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1532s\u001b[0m 6s/step - accuracy: 0.9335 - loss: 0.1779 - val_accuracy: 0.8478 - val_loss: 0.3777 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1520s\u001b[0m 6s/step - accuracy: 0.9301 - loss: 0.1791 - val_accuracy: 0.8718 - val_loss: 0.2984 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1558s\u001b[0m 6s/step - accuracy: 0.9319 - loss: 0.1726 - val_accuracy: 0.8974 - val_loss: 0.3005 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1586s\u001b[0m 7s/step - accuracy: 0.9318 - loss: 0.1760 - val_accuracy: 0.8429 - val_loss: 0.3918 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete and saved as pneumonia_detection.h5\n"
     ]
    }
   ],
   "source": [
    "# Image dimensions\n",
    "image_size = (512, 512)\n",
    "batch_size = 32\n",
    "\n",
    "# Image Data Generators (Rescaling & Augmentation)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    zoom_range=0.2\n",
    ")   \n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "# Define CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(512, 512,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification (Pneumonia vs Normal)\n",
    "])\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Reduce learning rate when the validation loss stops improving\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "\n",
    "# Compile model with a smaller initial learning rate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.0001)  # Start small\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train model\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=10, callbacks=[early_stop, lr_scheduler])\n",
    "\n",
    "# Save trained model\n",
    "model.save(\"pneumonia_detection.h5\")\n",
    "\n",
    "print(\"Model training complete and saved as pneumonia_detection.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NORMAL': 0, 'PNEUMONIA': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "NORMAL\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"pneumonia_detection.h5\")\n",
    "\n",
    "# Load and preprocess test image\n",
    "img_path = r\"C:\\Users\\Pc\\Pictures\\pneumon.jfif\"\n",
    "img = image.load_img(img_path, target_size=(512, 512))\n",
    "img_array = image.img_to_array(img) / 255.0\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(img_array)\n",
    "prediction\n",
    "\n",
    "if prediction > 0.5:\n",
    "    print(\"PNEUMONIA\")\n",
    "else:\n",
    "    print(\"NORMAL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMAL: 3883 images\n",
      "PNEUMONIA: 3883 images\n"
     ]
    }
   ],
   "source": [
    "def count_images(directory):\n",
    "    normal_count = len(os.listdir(os.path.join(directory, \"NORMAL\")))\n",
    "    pneumonia_count = len(os.listdir(os.path.join(directory, \"PNEUMONIA\")))\n",
    "    print(f\"NORMAL: {normal_count} images\")\n",
    "    print(f\"PNEUMONIA: {pneumonia_count} images\")\n",
    "    \n",
    "count_images(train_path)\n",
    "# count_images(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
